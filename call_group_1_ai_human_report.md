# Call Group 1 — AI & Human Collaboration Report

Date: 2025-11-30

## Project GitHub

Repository / project board: https://github.com/users/4qhyqyhktr-sudo/projects/1/views/1

**Executive Summary (100-150 words)**

This semester my collaboration with AI focused on operationalizing a school-level FluShot report card and an accompanying spatial alert system to increase vaccination uptake while protecting privacy and governance constraints. I used generative models to automate draft creation, mapping and CSV production, and relied on human judgment to set thresholds, verify data plausibility and translate technical outputs into policy actions for principals and the Education Bureau. The central lesson was that AI speeds ideation and formatting, but human direction determines ethical, feasible, and context-specific outcomes; when I constrained AI outputs with precise prompts and validation checks, the tools produced actionable artifacts that I could confidently refine and deploy in pilot outreach work.

**AI Usage Overview (200-250 words)**

My use of AI tools evolved from exploratory drafting to disciplined co‑production. At first I used ChatGPT and generative assistants to collect background literature, draft broad intervention ideas, and lay out possible dashboard elements without close constraints, which produced many plausible but non-specific outputs. Once the project demanded operational deliverables—`report_card.csv` templates, PNG maps, and a `flagged_schools_70pct.csv` for alerts—I moved to tightly structured, multi-part prompts and relied on GitHub Copilot for code scaffolding and debugging, combined with targeted questions to the generative model for policy framing. For data tasks I used AI to suggest column schemas, produce plotting code, and generate synthetic examples that helped test visual layouts. Over time my pattern became: prompt for a draft or code stub, inspect outputs for domain fit and parsing errors, request revisions that enforce privacy, and finalize artifacts after manual validation. This iterative approach let me shift time from mundane formatting to higher-value decisions such as setting alert thresholds, validating geographic placements, and writing clear guidance for principals on how to interpret the report card.

**Chat History Portfolio (Not counted in word limit)**

Phase: Early scoping — Excerpt: "Can you draft a school-level report card template showing vaccination rate, enrollment and URTI absence? Keep fields aggregated and non-identifying." Annotation: I asked this to move from theory to a practical data schema; the AI returned a template which I then modified to remove potentially identifying fields and add an eHealth verification column.

Phase: Mapping and alerts — Excerpt: "Generate Python code to plot schools on a map, color by vaccination_rate_pct, and output a CSV of schools with vaccination_rate_pct < 70." Annotation: This prompt produced a working map and `flagged_schools_70pct.csv`; I corrected an initial geographic clustering mistake introduced by the AI and specified the output columns required for operational follow-up.

Phase: Policy framing — Excerpt: "Suggest interventions to raise vaccination uptake using school outreach and PTA engagement; note privacy constraints." Annotation: The AI suggested public badges and incentives; I rejected public disclosure and asked for internal-reporting alternatives that link to eHealth verification and targeted PTA-led outreach pilots.

**Reflection on Human-AI Collaboration (400-500 words)**

The core of my learning was discovering and practicing the precise role humans must play when collaborating with generative systems: we are specification designers, critical interrogators, and ethical overseers. At the start of the semester I treated the AI as a fast researcher and drafter, accepting clean prose and code stubs at face value; that approach failed me when a script recommending public disclosure and simplistic incentives initially slipped into the policy memo, revealing both logical gaps and contextual naivety. That early failure was pivotal because it forced me to adopt a posture of sustained skepticism and layered validation. I learned to decompose tasks into discrete, verifiable steps: define data inputs and allowed outputs, constrain AI prompts with governance and audience requirements, and require explicit validation checks for every principal-facing artifact. Practically this meant I would not accept a `report_card.csv` until I had confirmed that fields were aggregated, that any identifiers could be pseudonymized, and that alerts would cross-check with eHealth or manual confirmation to avoid false positives. My unique human contributions were several and complementary. I supplied institutional knowledge about Hong Kong’s education and public-health data flows that the AI could not infer, I judged political and legal feasibility in ways the model could not, and I designed pilot-friendly operational steps (for example, prioritizing schools with active PTA engagement for outreach pilots). I also acted as a reasoning engine: rather than using the AI solely to surface facts, I set up adversarial prompts asking the model to critique its own proposals, compare alternatives, and present counterarguments; this dialogic use forced the model to surface assumptions and allowed me to pick the most defensible course. On the technical side, I developed simple diagnostics for model outputs—spot-checking geographic coordinates, checking distributional plausibility for vaccination rates, and asking for robustness checks when regression diagnostics suggested multicollinearity—reducing the risk of overconfident interpretation. Ethically, I treated the AI as a tool that accelerates options but never replaces governance judgments: the choice to keep report cards internal, to require eHealth verification, and to build a manual confirmation step for alerts were all human decisions rooted in privacy and trust. Collaboration dynamics shifted over time: AI handled drafting, formatting, and rapid scenario expansion, while I focused on specification, validation, stakeholder framing, and governance design. This division increased productivity without ceding responsibility. The result was a set of artifacts—cleaned CSVs, maps, and principal-ready PNGs—that were technically coherent, policy-sensitive, and ready for a pilot that respects both operational constraints and privacy.

**Learning Outcomes and Transferable Skills (150-200 words)**

Working with AI trained me in precise problem specification, iterative validation, and ethical framing—skills that transfer directly to policy work and data-driven projects. I became better at writing prompts that anticipate failure modes, at constructing small validation pipelines to catch parsing or geographic errors, and at translating analytic outputs into clear guidance for non-technical stakeholders. AI accelerated my drafting speed, which freed time for stakeholder engagement and governance design; however, it also revealed limits—models can hallucinate plausible-sounding but incorrect suggestions and struggle with local policy nuance—so I now pair rapid generation with adversarial questioning and manual confirmation steps. In future projects I will apply this approach by using AI for routine production and scenario-building while reserving final decisions and ethical judgments for human review, and by embedding simple validation checks and documentation into every deliverable to support transparent, accountable policy use.

